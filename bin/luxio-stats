#!/usr/bin/env python3

"""
This file is used for three purposes:
    1) To preprocess a trace dataset
    2) Identify important features relating to I/O performance
    3) To identify classes of I/O behavior based on those features
"""

import sys,os
import pandas as pd
import numpy as np

from luxio.io_requirement_extractor.trace_parser.trace_parser_factory import *
from luxio.storage_requirement_builder.models import AppClassifier, StorageClassifier
from luxio.common.configuration_manager import *
from clever.dataset import *
from clever.models.regression.forest import *
from clever.models.regression.ensemble import *
from clever.models.cluster import *
from clever.transformers import *
from clever.feature_selection import *
from clever.metrics import *
import argparse, configparser
import pprint, warnings

pp = pprint.PrettyPrinter(depth=6)

class ArgumentParser:
    def __init__(self):
        use_cases = [
            "preprocess", "preliminary", "dataset_split", "app_reg", "qosa_reg",
            "app_reg_stats", "qosa_reg_stats", "app_gen", "qosa_gen", "app_gen_stats",
            "qosa_gen_stats", "filter", 'all'
        ]
        self.parser = argparse.ArgumentParser()
        self.parser.add_argument("-t", default=None, help=f"What your use case is: {use_cases}")
        self.parser.add_argument("-c", default="sample/stats_conf/conf.ini", help="The properties file containing model paths and config parameters")
        self.parser.add_argument("-d", default="ARGONNE", help="Which data to be preprocessed: ARGONNE")

    def parse(self):
        args = self.parser.parse_args()
        self.tool = args.t
        self.conf = configparser.ConfigParser()
        self.conf.read(args.c)
        return self

#Dataset preprocessing
def preprocess_dataset(params):
    conf = ConfigurationManager.get_instance()
    conf.__dict__.update(params)
    dataset = params["dataset_type"]
    parser = TraceParserFactory(TraceParserType[dataset])
    df = parser.preprocess()
    df.to_pickle(params["out"])

#Preliminary analysis of a dataset
def preliminary_analysis(params):
    df = pd.read_csv(params["trace"])
    analysis = pd.DataFrame(df.clever.analyze())
    pp.pprint(analysis)
    analysis.to_csv(params["trace_analysis"])

#Performance partitioner
def performance_partitioner(params):
    PERFORMANCE = pd.DataFrame().clever.load_features(params["vars"])
    df = pd.read_csv(params["trace"])
    #Partition the different performance variables
    partitioners = KResolutionReducer(k=4).fit(np.array(LogTransformer(base=10,add=1).transform(df[PERFORMANCE])))
    partitioners.save(params["perf_partitions"])
    #Create the training and testing datasets
    train_df,hyper_df,test_df = df.clever.random_sample(.5, .2)
    train_df.to_pickle(params["train"])
    hyper_df.to_pickle(params["hyper"])
    test_df.to_pickle(params["test"])
    return partitioners, train_df, hyper_df, test_df

#Feature selection module
def feature_selector(params):
    FEATURES = pd.DataFrame().clever.load_features(params["features"])
    PERFORMANCE = pd.DataFrame().clever.load_features(params["vars"])

    #Load the training and testing datasets
    try:
        partitioners = KResolutionReducer.load(params["perf_partitions"])
        train_df = pd.read_pickle(params["train"])
        hyper_df = pd.read_pickle(params["hyper"])
        test_df = pd.read_pickle(params["test"])
    except:
        partitioners, train_df, hyper_df, test_df = performance_partitioner(params)

    #Divide the datasets into x and y
    train_x,train_y = train_df.clever.split(FEATURES,PERFORMANCE)
    hyper_x,hyper_y = hyper_df.clever.split(FEATURES,PERFORMANCE)
    test_x,test_y = test_df.clever.split(FEATURES,PERFORMANCE)

    #Train model for each variable and select minimum feature set
    fs = FeatureSelector(
        FEATURES,
        PERFORMANCE,
        [XGBRegressor(
            transform_y=LogTransformer(base=10,add=1),
            fitness_metric=PartitionedMetric(partitioner, score=RelativeAccuracyMetric(scale=1, add=1)),
            error_metric=PartitionedMetric(partitioner, score=RMLSEMetric(add=1))
        ) for partitioner in partitioners.segments_]
    )

    fs.select(
        train_x, train_y, hyper_x, hyper_y,
        max_iter=10,
        max_tunes=0,
        max_tune_iter=0,
        growth=.5,
        acc_loss=.05,
        thresh=.02)

    #Save and analyze
    fs.save(params["selector"])
    fs.model_.save(params["regressor"])
    fs.save_importances(params["importances"])
    pp.pprint(fs.analyze(test_x,test_y))

#Feature selection statistics module
def feature_selector_stats(params):
    FEATURES = pd.DataFrame().clever.load_features(params["features"])
    PERFORMANCE = pd.DataFrame().clever.load_features(params["vars"])
    #Create the training and testing datasets
    partitioners = KResolutionReducer.load(params["perf_partitions"])
    train_df = pd.read_pickle(params["train"])
    hyper_df = pd.read_pickle(params["hyper"])
    test_df = pd.read_pickle(params["test"])
    #Divide the datasets into x and y
    train_x,train_y = train_df.clever.split(FEATURES,PERFORMANCE)
    hyper_x,hyper_y = hyper_df.clever.split(FEATURES,PERFORMANCE)
    test_x,test_y = test_df.clever.split(FEATURES,PERFORMANCE)
    #Load the feature selector
    fs = FeatureSelector.load(params["selector"])
    fs.model_._calculate_metrics()
    analysis = fs.analyze(test_x, test_y, metrics=[{
        "r2" : r2Metric(),
        "RelativeError" : PartitionedMetric(partitioner, score=RelativeErrorMetric(add=1), mode='all'),
        "RMLSE" : PartitionedMetric(partitioner, score=RMLSEMetric(add=1), mode='all'),
    } for partitioner in partitioners.segments_])
    pp.pprint(analysis)
    fs.save(params["selector"])
    fs.model_.save(params["regressor"])
    fs.save_importances(params["importances"])

#Application Behavior Classifaction module
def app_behavior_classifier(params):
    df = pd.read_csv(params["trace"])
    feature_importances = pd.read_csv(params["importances"], index_col=0)
    bc = AppClassifier(feature_importances)
    bc.fit(df)
    bc.save(params["classifier"])

#Storage Behavior Classifaction module
def storage_behavior_classifier(params):
    df = pd.read_csv(params["trace"])
    feature_importances = pd.DataFrame()
    bc = StorageClassifier(feature_importances)
    bc.fit(df)
    bc.save(params["classifier"])

#Behavior Classification statistics module
def behavior_classifier_stats(params):
    bc = BehaviorClassifier.load(params["classifier"])
    analysis = bc.analyze(dir="datasets/model_analysis")
    #pp.pprint(analysis)
    #bc.visualize()

#Filter out QoSAs
def filter_qosas(app_params, storage_params):
    ac = AppClassifier.load(app_params["classifier"])
    sc = StorageClassifier.load(storage_params["classifier"])
    ac.filter_qosas(sc)
    ac.save(app_params["classifier"])

##############MAIN##################
if __name__ == "__main__":
    args = ArgumentParser().parse()

    if args.tool == "preprocess":
        preprocess_dataset(args.conf["PREPROCESS"])

    if args.tool == "preliminary":
        preliminary_analysis(args.conf["PREPROCESS"])

    if args.tool == "dataset_split" or args.tool == "all":
        performance_partitioner(args.conf["APP_BEHAVIOR_MODEL"])

    if args.tool == "app_reg" or args.tool == "all":
        feature_selector(args.conf["APP_BEHAVIOR_MODEL"])
    if args.tool == "app_reg_stats" or args.tool == "all" or args.tool == "app_reg":
        feature_selector_stats(args.conf["APP_BEHAVIOR_MODEL"])

    if args.tool == "qosa_reg" or args.tool == "all":
        feature_selector(args.conf["STORAGE_BEHAVIOR_MODEL"])
    if args.tool == "qosa_reg_stats" or args.tool == "all" or args.tool == "qosa_reg":
        feature_selector_stats(args.conf["STORAGE_BEHAVIOR_MODEL"])

    if args.tool == "app_gen" or args.tool == "all":
        app_behavior_classifier(args.conf["APP_BEHAVIOR_MODEL"])
    if args.tool == "app_gen_stats" or args.tool == "all" or args.tool == "app_gen":
        behavior_classifier_stats(args.conf["APP_BEHAVIOR_MODEL"])

    if args.tool == "qosa_gen" or args.tool == "all":
        storage_behavior_classifier(args.conf["STORAGE_BEHAVIOR_MODEL"])
    if args.tool == "qosa_gen_stats" or args.tool == "all" or args.tool == "qosa_gen":
        behavior_classifier_stats(args.conf["STORAGE_BEHAVIOR_MODEL"])

    if args.tool == "filter" or args.tool == "all":
        filter_qosas(args.conf["APP_BEHAVIOR_MODEL"], args.conf["STORAGE_BEHAVIOR_MODEL"])
